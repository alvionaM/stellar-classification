{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xlrd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23700/3501731938.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatistics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xlrd'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "from statistics import mode\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Purpose Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance:\n",
    "    @staticmethod\n",
    "    def squared_euclidean_distance(X,y):\n",
    "        # Tile the vector y to create a matrix with the same number \n",
    "        # of rows as X and the same number of columns as y\n",
    "        y = np.tile(y, (X.shape[0], 1))\n",
    "        \n",
    "        # Calculate the squared Euclidean distance between each row of x and y\n",
    "        squared_distance = np.square(X - y).sum(axis=1)\n",
    "        \n",
    "        return squared_distance\n",
    "\n",
    "    @staticmethod\n",
    "    def euclidean_distance(X, y):\n",
    "        squared_distance = Distance.squared_euclidean_distance(X,y)\n",
    "        \n",
    "        # Take the square root to get the Euclidean distance\n",
    "        distance = np.sqrt(squared_distance)\n",
    "    \n",
    "        return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Curve:\n",
    "    @staticmethod\n",
    "    def cross_validation_cost_evolution_curve(caption, costs):\n",
    "        # Select best hyperparameter\n",
    "        param = np.argmin(costs) + 1\n",
    "\n",
    "        # Plot the evolution of the validation error with respect to the best hyperparameter\n",
    "        plt.plot(range(1, len(costs)+1), costs * 100, marker='o', color='crimson')\n",
    "        plt.title('K-fold cross validation error evolution')\n",
    "        plt.ylabel('Average Validation Error %')\n",
    "        plt.xlabel(caption)\n",
    "        plt.show()\n",
    "        return param\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy_evolution_curve(caption, accuracies):\n",
    "        # Select best hyperparameter\n",
    "        param = np.argmax(accuracies) + 1\n",
    "\n",
    "        # Plot the evolution of the validation error with respect to the best hyperparameter\n",
    "        plt.plot(range(1, len(accuracies)+1), accuracies, marker='o', color='darkslateblue')\n",
    "        plt.title('Accuracy evolution')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel(caption)\n",
    "        plt.show()\n",
    "        return param\n",
    "    \n",
    "    @staticmethod\n",
    "    def EM_alg_cost_evolution_curve(costs):\n",
    "        total_iterations = len(costs)//2\n",
    "\n",
    "        # Plot the evolution of the cost function\n",
    "        for i in range(2*total_iterations-1):\n",
    "            # Alternate the marker color for costs calculated after an expectation step (even position) \n",
    "            # or a maximization step (odd position)\n",
    "            color = 'darkslateblue' if i % 2 == 0 else 'crimson'\n",
    "            label='After Expectation Step' if i == 0 else 'After Maximization Step' if i == 1 else ''\n",
    "            plt.plot([i, i+1], [costs[i], costs[i+1]], marker='o', mfc=color, mec=color, ms='7', ls=':', color='black', label=label)\n",
    "        last_point = 2*total_iterations-1\n",
    "        plt.plot(last_point, costs[last_point], marker='o', mfc='crimson', mec='crimson', ms='7')\n",
    "\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Cost')\n",
    "        plt.suptitle('K-means cost evolution', y=1.03)\n",
    "        plt.title(r'Cost function: $\\frac{1}{2}\\sum_{i=1}^{N} ||\\mathbf{x}_{i} - \\mathbf{\\hat\\mu}_{\\hat y_{i}}||^{2}$')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "        iterations_ticks = [val for i in range(1, total_iterations + 1) for val in ['', i]]\n",
    "        plt.xticks(range(2*total_iterations), iterations_ticks)\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "        # Construct reporting table\n",
    "        data = []\n",
    "\n",
    "        for i in range(len(costs)):\n",
    "            iter = str(i//2)+'a' if i%2==0 else str(i//2)+'b'  # Increasing index for every 2 rows\n",
    "            step = 'E-step' if i % 2 == 0 else 'M-step'\n",
    "            cost = costs[i]\n",
    "            data.append({'Iteration': iter, 'Step': step, 'Cost': cost})\n",
    "\n",
    "        cost_evolution = pd.concat([pd.DataFrame([d]) for d in data], ignore_index=True).set_index('Iteration')\n",
    "\n",
    "        return cost_evolution\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Report:\n",
    "    @staticmethod\n",
    "    def gaussian_naive_bayes_parameters(caption, priors, means, covariance_matrix, num_classes, num_features):\n",
    "        \n",
    "        print(caption,\"- Priors\")\n",
    "        custom_priors_df = pd.DataFrame(priors.reshape(1, -1), columns=[f'Class_{i}' for i in range(num_classes)])\n",
    "        display(custom_priors_df)\n",
    "\n",
    "        print(caption,\" - Means\")\n",
    "        custom_means_df = pd.DataFrame(means, columns=[f'Feature_{i}' for i in range(num_features)], index=[f'Class_{i}' for i in range(num_classes)])\n",
    "        display(custom_means_df)\n",
    "\n",
    "        print(caption,\" - Covariance Matrix per class\")\n",
    "        for covariance in covariance_matrix:\n",
    "            custom_covariance_df = pd.DataFrame(covariance, columns=[f'Feature_{i}' for i in range(num_features)], index=[f'Feature_{i}' for i in range(num_features)])\n",
    "            display(custom_covariance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the User Modeling Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\trian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xlrd'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23700/2445013673.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muser_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../resources/user+knowledge+modeling/Data_User_Modeling_Dataset_Hamdi Tolga KAHRAMAN.xls\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\trian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mc:\\Users\\trian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1693\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\excel\\_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \"\"\"\n\u001b[0;32m     33\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"xlrd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trian\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\compat\\_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd."
     ]
    }
   ],
   "source": [
    "user_data = pd.read_excel(\"../resources/user+knowledge+modeling/Data_User_Modeling_Dataset_Hamdi Tolga KAHRAMAN.xls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target\n",
       "0           5.1                3.5               1.4                0.2           0  \n",
       "1           4.9                3.0               1.4                0.2           0  \n",
       "2           4.7                3.2               1.3                0.2           0  \n",
       "3           4.6                3.1               1.5                0.2           0  \n",
       "4           5.0                3.6               1.4                0.2           0  \n",
       "5           5.4                3.9               1.7                0.4           0  \n",
       "6           4.6                3.4               1.4                0.3           0  \n",
       "7           5.0                3.4               1.5                0.2           0  \n",
       "8           4.4                2.9               1.4                0.2           0  \n",
       "9           4.9                3.1               1.5                0.1           0  \n",
       "10          5.4                3.7               1.5                0.2           0  \n",
       "11          4.8                3.4               1.6                0.2           0  \n",
       "12          4.8                3.0               1.4                0.1           0  \n",
       "13          4.3                3.0               1.1                0.1           0  \n",
       "14          5.8                4.0               1.2                0.2           0  \n",
       "15          5.7                4.4               1.5                0.4           0  \n",
       "16          5.4                3.9               1.3                0.4           0  \n",
       "17          5.1                3.5               1.4                0.3           0  \n",
       "18          5.7                3.8               1.7                0.3           0  \n",
       "19          5.1                3.8               1.5                0.3           0  \n",
       "20          5.4                3.4               1.7                0.2           0  \n",
       "21          5.1                3.7               1.5                0.4           0  \n",
       "22          4.6                3.6               1.0                0.2           0  \n",
       "23          5.1                3.3               1.7                0.5           0  \n",
       "24          4.8                3.4               1.9                0.2           0  \n",
       "25          5.0                3.0               1.6                0.2           0  \n",
       "26          5.0                3.4               1.6                0.4           0  \n",
       "27          5.2                3.5               1.5                0.2           0  \n",
       "28          5.2                3.4               1.4                0.2           0  \n",
       "29          4.7                3.2               1.6                0.2           0  \n",
       "30          4.8                3.1               1.6                0.2           0  \n",
       "31          5.4                3.4               1.5                0.4           0  \n",
       "32          5.2                4.1               1.5                0.1           0  \n",
       "33          5.5                4.2               1.4                0.2           0  \n",
       "34          4.9                3.1               1.5                0.2           0  \n",
       "35          5.0                3.2               1.2                0.2           0  \n",
       "36          5.5                3.5               1.3                0.2           0  \n",
       "37          4.9                3.6               1.4                0.1           0  \n",
       "38          4.4                3.0               1.3                0.2           0  \n",
       "39          5.1                3.4               1.5                0.2           0  \n",
       "40          5.0                3.5               1.3                0.3           0  \n",
       "41          4.5                2.3               1.3                0.3           0  \n",
       "42          4.4                3.2               1.3                0.2           0  \n",
       "43          5.0                3.5               1.6                0.6           0  \n",
       "44          5.1                3.8               1.9                0.4           0  \n",
       "45          4.8                3.0               1.4                0.3           0  \n",
       "46          5.1                3.8               1.6                0.2           0  \n",
       "47          4.6                3.2               1.4                0.2           0  \n",
       "48          5.3                3.7               1.5                0.2           0  \n",
       "49          5.0                3.3               1.4                0.2           0  \n",
       "50          7.0                3.2               4.7                1.4           1  \n",
       "51          6.4                3.2               4.5                1.5           1  \n",
       "52          6.9                3.1               4.9                1.5           1  \n",
       "53          5.5                2.3               4.0                1.3           1  \n",
       "54          6.5                2.8               4.6                1.5           1  \n",
       "55          5.7                2.8               4.5                1.3           1  \n",
       "56          6.3                3.3               4.7                1.6           1  \n",
       "57          4.9                2.4               3.3                1.0           1  \n",
       "58          6.6                2.9               4.6                1.3           1  \n",
       "59          5.2                2.7               3.9                1.4           1  \n",
       "60          5.0                2.0               3.5                1.0           1  \n",
       "61          5.9                3.0               4.2                1.5           1  \n",
       "62          6.0                2.2               4.0                1.0           1  \n",
       "63          6.1                2.9               4.7                1.4           1  \n",
       "64          5.6                2.9               3.6                1.3           1  \n",
       "65          6.7                3.1               4.4                1.4           1  \n",
       "66          5.6                3.0               4.5                1.5           1  \n",
       "67          5.8                2.7               4.1                1.0           1  \n",
       "68          6.2                2.2               4.5                1.5           1  \n",
       "69          5.6                2.5               3.9                1.1           1  \n",
       "70          5.9                3.2               4.8                1.8           1  \n",
       "71          6.1                2.8               4.0                1.3           1  \n",
       "72          6.3                2.5               4.9                1.5           1  \n",
       "73          6.1                2.8               4.7                1.2           1  \n",
       "74          6.4                2.9               4.3                1.3           1  \n",
       "75          6.6                3.0               4.4                1.4           1  \n",
       "76          6.8                2.8               4.8                1.4           1  \n",
       "77          6.7                3.0               5.0                1.7           1  \n",
       "78          6.0                2.9               4.5                1.5           1  \n",
       "79          5.7                2.6               3.5                1.0           1  \n",
       "80          5.5                2.4               3.8                1.1           1  \n",
       "81          5.5                2.4               3.7                1.0           1  \n",
       "82          5.8                2.7               3.9                1.2           1  \n",
       "83          6.0                2.7               5.1                1.6           1  \n",
       "84          5.4                3.0               4.5                1.5           1  \n",
       "85          6.0                3.4               4.5                1.6           1  \n",
       "86          6.7                3.1               4.7                1.5           1  \n",
       "87          6.3                2.3               4.4                1.3           1  \n",
       "88          5.6                3.0               4.1                1.3           1  \n",
       "89          5.5                2.5               4.0                1.3           1  \n",
       "90          5.5                2.6               4.4                1.2           1  \n",
       "91          6.1                3.0               4.6                1.4           1  \n",
       "92          5.8                2.6               4.0                1.2           1  \n",
       "93          5.0                2.3               3.3                1.0           1  \n",
       "94          5.6                2.7               4.2                1.3           1  \n",
       "95          5.7                3.0               4.2                1.2           1  \n",
       "96          5.7                2.9               4.2                1.3           1  \n",
       "97          6.2                2.9               4.3                1.3           1  \n",
       "98          5.1                2.5               3.0                1.1           1  \n",
       "99          5.7                2.8               4.1                1.3           1  \n",
       "100         6.3                3.3               6.0                2.5           2  \n",
       "101         5.8                2.7               5.1                1.9           2  \n",
       "102         7.1                3.0               5.9                2.1           2  \n",
       "103         6.3                2.9               5.6                1.8           2  \n",
       "104         6.5                3.0               5.8                2.2           2  \n",
       "105         7.6                3.0               6.6                2.1           2  \n",
       "106         4.9                2.5               4.5                1.7           2  \n",
       "107         7.3                2.9               6.3                1.8           2  \n",
       "108         6.7                2.5               5.8                1.8           2  \n",
       "109         7.2                3.6               6.1                2.5           2  \n",
       "110         6.5                3.2               5.1                2.0           2  \n",
       "111         6.4                2.7               5.3                1.9           2  \n",
       "112         6.8                3.0               5.5                2.1           2  \n",
       "113         5.7                2.5               5.0                2.0           2  \n",
       "114         5.8                2.8               5.1                2.4           2  \n",
       "115         6.4                3.2               5.3                2.3           2  \n",
       "116         6.5                3.0               5.5                1.8           2  \n",
       "117         7.7                3.8               6.7                2.2           2  \n",
       "118         7.7                2.6               6.9                2.3           2  \n",
       "119         6.0                2.2               5.0                1.5           2  \n",
       "120         6.9                3.2               5.7                2.3           2  \n",
       "121         5.6                2.8               4.9                2.0           2  \n",
       "122         7.7                2.8               6.7                2.0           2  \n",
       "123         6.3                2.7               4.9                1.8           2  \n",
       "124         6.7                3.3               5.7                2.1           2  \n",
       "125         7.2                3.2               6.0                1.8           2  \n",
       "126         6.2                2.8               4.8                1.8           2  \n",
       "127         6.1                3.0               4.9                1.8           2  \n",
       "128         6.4                2.8               5.6                2.1           2  \n",
       "129         7.2                3.0               5.8                1.6           2  \n",
       "130         7.4                2.8               6.1                1.9           2  \n",
       "131         7.9                3.8               6.4                2.0           2  \n",
       "132         6.4                2.8               5.6                2.2           2  \n",
       "133         6.3                2.8               5.1                1.5           2  \n",
       "134         6.1                2.6               5.6                1.4           2  \n",
       "135         7.7                3.0               6.1                2.3           2  \n",
       "136         6.3                3.4               5.6                2.4           2  \n",
       "137         6.4                3.1               5.5                1.8           2  \n",
       "138         6.0                3.0               4.8                1.8           2  \n",
       "139         6.9                3.1               5.4                2.1           2  \n",
       "140         6.7                3.1               5.6                2.4           2  \n",
       "141         6.9                3.1               5.1                2.3           2  \n",
       "142         5.8                2.7               5.1                1.9           2  \n",
       "143         6.8                3.2               5.9                2.3           2  \n",
       "144         6.7                3.3               5.7                2.5           2  \n",
       "145         6.7                3.0               5.2                2.3           2  \n",
       "146         6.3                2.5               5.0                1.9           2  \n",
       "147         6.5                3.0               5.2                2.0           2  \n",
       "148         6.2                3.4               5.4                2.3           2  \n",
       "149         5.9                3.0               5.1                1.8           2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = load_iris(as_frame=True)\n",
    "iris_data.frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split initial data into train and test (50 examples for test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data.to_numpy(), \n",
    "                                                    iris_data.target.to_numpy(), \n",
    "                                                    test_size=50, random_state=42)\n",
    "\n",
    "\n",
    "# split rest of the train data into train and dev (50 examples for dev)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, \n",
    "                                                  test_size=50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom kNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we implement the well-known kNN algorithm. Note that the Euclidean distance is used as the distance metric for measuring the distance between test set examples and train set examples. Next, two functions are included for finding the best value for the hyperparameter ($k$):\n",
    "\n",
    "1. Cross Validation Method (`k_fold_cross_validation`):\n",
    "This method performs cross-validation to find the best value for the hyperparameter $k$. It sets the error each time as the average validation error (across all folds in which the train set is divided each time). Finally, it returns the value of $k$ that resulted in the smallest error.\n",
    "\n",
    "2. Accuracy-based Validation Method (`accuracy_based_validation`):\n",
    "This method returns the first value of $k$ that provides the best accuracy on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN:\n",
    "    def __init__(self, k):\n",
    "        # k nearest neighbours hyperparameter\n",
    "        self.k = k\n",
    "\n",
    "        # X_train: n*m matrix (n examples, m features)\n",
    "        # X[i] = [xi1, xi2, ..., xim] for i=1 to n\n",
    "        self.X_train = None\n",
    "        \n",
    "        # y_train: n*1 vector (class of each example)\n",
    "        # y[i] = class of X[i]  for i=1 to n\n",
    "        self.y_train = None\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        Ntest = X_test.shape[0]\n",
    "        predicted_classes = list()\n",
    "\n",
    "        for test_example_idx in range(Ntest):\n",
    "            # Calculate the distance for all train examples\n",
    "            d = Distance.euclidean_distance(self.X_train, X_test[test_example_idx,:])\n",
    "\n",
    "            # Return the indices of the K closest instances\n",
    "            k_closest = np.argsort(d)[:self.k]\n",
    "\n",
    "            # Find the classes of the k closest instances\n",
    "            y = self.y_train[k_closest]\n",
    "\n",
    "            # mode: returns the most frequent (majority vote)\n",
    "            predicted_classes.append(mode(y))\n",
    "\n",
    "        return np.array(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(K, numFolds, X, y):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation for kNN.\n",
    "\n",
    "    Parameters:\n",
    "    - K: Number of nearest neighbors to test.\n",
    "    - numFolds: Number of folds for cross-validation.\n",
    "    - X: Training data features.\n",
    "    - y: Labels for the training data.\n",
    "\n",
    "    Returns:\n",
    "    - best_k: Best k value based on cross-validation.\n",
    "    \"\"\"\n",
    "\n",
    "    N = X.shape[0]\n",
    "    np.random.seed(10)\n",
    "    perm = np.random.permutation(N)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "\n",
    "    chunk_size = int(N / numFolds)\n",
    "    split_indices = np.arange(chunk_size, chunk_size * numFolds, chunk_size)\n",
    "\n",
    "    if chunk_size * numFolds < N:\n",
    "        split_indices[-1] = N - 1\n",
    "    else:\n",
    "        last_chunk = chunk_size\n",
    "\n",
    "    Xfolds = np.vsplit(X, split_indices)\n",
    "    yfolds = np.hsplit(y, split_indices)\n",
    "\n",
    "    errors = np.zeros((K, numFolds))\n",
    "\n",
    "    for k in tqdm(range(1, K + 1)):\n",
    "        for j in range(numFolds):\n",
    "            X_train = np.vstack([Xfolds[i] for i in range(len(Xfolds)) if i != j])\n",
    "            y_train = np.hstack([yfolds[i] for i in range(len(yfolds)) if i != j])\n",
    "            X_test = Xfolds[j]\n",
    "\n",
    "            knn = kNN(k)\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_test = knn.predict(X_test)\n",
    "\n",
    "            # Compute the percent misclassified data points\n",
    "            errors[k - 1, j] = np.count_nonzero(y_test != yfolds[j]) / X_test.shape[0]\n",
    "            print(\"kNN for k = {}, fold # {}, error = {} \".format(k, j, errors[k - 1, j]))\n",
    "\n",
    "    val = errors.sum(axis=1) / numFolds\n",
    "\n",
    "    best_k = Curve.cross_validation_cost_evolution_curve(\"k Nearest Neighbours\", val)\n",
    "    \n",
    "    print('Smallest average error:', val[best_k - 1])\n",
    "    print('Best k:', best_k)\n",
    "\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_based_validation(K, X_train, y_train, X_dev, y_dev):\n",
    "  \"\"\"\n",
    "  Perform accuracy-based validation for the kNN algorithm.\n",
    "\n",
    "  Parameters:\n",
    "  - K: Number of nearest neighbors to test.\n",
    "  - X_train: Training data features.\n",
    "  - y_train: Labels for the training data.\n",
    "  - X_dev: Development data features for validation.\n",
    "  - y_dev: Labels for the development data.\n",
    "\n",
    "  Returns:\n",
    "  - best_k: The value of k that achieved the highest accuracy on the development data.\n",
    "  \"\"\"\n",
    "    \n",
    "  accuracies = np.zeros(K)\n",
    "\n",
    "  for k in tqdm(range(1, K + 1)):\n",
    "    knn = kNN(k)  # knn object with current k\n",
    "    knn.fit(X_train, y_train) # fit with current k in the training data\n",
    "\n",
    "    predictions = knn.predict(X_dev) # predict with current k using the development data\n",
    "    accuracy = accuracy_score(y_dev, predictions) # count accuracy\n",
    "    accuracies[k - 1] = accuracy\n",
    "    \n",
    "    print('Accuracy for k={0}: {1}'.format(k, accuracy))\n",
    "    \n",
    "  best_k = Curve.accuracy_evolution_curve(\"k Nearest Neighbours\", accuracies)\n",
    "    \n",
    "  print('Best dev accuracy:', accuracies[best_k - 1])\n",
    "  print('Best k:', best_k)\n",
    "\n",
    "  return best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal value of the hyperparameter $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we find the optimal value of the hyperparameter $k$ in the range [1, 10] -using both functions defined previously (`k_fold_cross_validation` and `accuracy_based_validation`)- and present our results for each value of $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `k_fold_cross_validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 370.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN for k = 1, fold # 0, error = 0.0 \n",
      "kNN for k = 1, fold # 1, error = 0.0 \n",
      "kNN for k = 1, fold # 2, error = 0.0 \n",
      "kNN for k = 1, fold # 3, error = 0.2 \n",
      "kNN for k = 1, fold # 4, error = 0.0 \n",
      "kNN for k = 1, fold # 5, error = 0.0 \n",
      "kNN for k = 1, fold # 6, error = 0.0 \n",
      "kNN for k = 1, fold # 7, error = 0.0 \n",
      "kNN for k = 1, fold # 8, error = 0.2 \n",
      "kNN for k = 1, fold # 9, error = 0.0 \n",
      "kNN for k = 2, fold # 0, error = 0.0 \n",
      "kNN for k = 2, fold # 1, error = 0.0 \n",
      "kNN for k = 2, fold # 2, error = 0.0 \n",
      "kNN for k = 2, fold # 3, error = 0.2 \n",
      "kNN for k = 2, fold # 4, error = 0.0 \n",
      "kNN for k = 2, fold # 5, error = 0.0 \n",
      "kNN for k = 2, fold # 6, error = 0.0 \n",
      "kNN for k = 2, fold # 7, error = 0.0 \n",
      "kNN for k = 2, fold # 8, error = 0.2 \n",
      "kNN for k = 2, fold # 9, error = 0.0 \n",
      "kNN for k = 3, fold # 0, error = 0.0 \n",
      "kNN for k = 3, fold # 1, error = 0.0 \n",
      "kNN for k = 3, fold # 2, error = 0.0 \n",
      "kNN for k = 3, fold # 3, error = 0.2 \n",
      "kNN for k = 3, fold # 4, error = 0.0 \n",
      "kNN for k = 3, fold # 5, error = 0.0 \n",
      "kNN for k = 3, fold # 6, error = 0.0 \n",
      "kNN for k = 3, fold # 7, error = 0.0 \n",
      "kNN for k = 3, fold # 8, error = 0.0 \n",
      "kNN for k = 3, fold # 9, error = 0.0 \n",
      "kNN for k = 4, fold # 0, error = 0.0 \n",
      "kNN for k = 4, fold # 1, error = 0.0 \n",
      "kNN for k = 4, fold # 2, error = 0.0 \n",
      "kNN for k = 4, fold # 3, error = 0.2 \n",
      "kNN for k = 4, fold # 4, error = 0.0 \n",
      "kNN for k = 4, fold # 5, error = 0.0 \n",
      "kNN for k = 4, fold # 6, error = 0.0 \n",
      "kNN for k = 4, fold # 7, error = 0.0 \n",
      "kNN for k = 4, fold # 8, error = 0.0 \n",
      "kNN for k = 4, fold # 9, error = 0.0 \n",
      "kNN for k = 5, fold # 0, error = 0.0 \n",
      "kNN for k = 5, fold # 1, error = 0.0 \n",
      "kNN for k = 5, fold # 2, error = 0.0 \n",
      "kNN for k = 5, fold # 3, error = 0.0 \n",
      "kNN for k = 5, fold # 4, error = 0.2 \n",
      "kNN for k = 5, fold # 5, error = 0.0 \n",
      "kNN for k = 5, fold # 6, error = 0.0 \n",
      "kNN for k = 5, fold # 7, error = 0.0 \n",
      "kNN for k = 5, fold # 8, error = 0.0 \n",
      "kNN for k = 5, fold # 9, error = 0.0 \n",
      "kNN for k = 6, fold # 0, error = 0.0 \n",
      "kNN for k = 6, fold # 1, error = 0.0 \n",
      "kNN for k = 6, fold # 2, error = 0.0 \n",
      "kNN for k = 6, fold # 3, error = 0.0 \n",
      "kNN for k = 6, fold # 4, error = 0.0 \n",
      "kNN for k = 6, fold # 5, error = 0.0 \n",
      "kNN for k = 6, fold # 6, error = 0.0 \n",
      "kNN for k = 6, fold # 7, error = 0.0 \n",
      "kNN for k = 6, fold # 8, error = 0.0 \n",
      "kNN for k = 6, fold # 9, error = 0.0 \n",
      "kNN for k = 7, fold # 0, error = 0.0 \n",
      "kNN for k = 7, fold # 1, error = 0.0 \n",
      "kNN for k = 7, fold # 2, error = 0.0 \n",
      "kNN for k = 7, fold # 3, error = 0.0 \n",
      "kNN for k = 7, fold # 4, error = 0.2 \n",
      "kNN for k = 7, fold # 5, error = 0.0 \n",
      "kNN for k = 7, fold # 6, error = 0.0 \n",
      "kNN for k = 7, fold # 7, error = 0.0 \n",
      "kNN for k = 7, fold # 8, error = 0.0 \n",
      "kNN for k = 7, fold # 9, error = 0.0 \n",
      "kNN for k = 8, fold # 0, error = 0.0 \n",
      "kNN for k = 8, fold # 1, error = 0.0 \n",
      "kNN for k = 8, fold # 2, error = 0.0 \n",
      "kNN for k = 8, fold # 3, error = 0.0 \n",
      "kNN for k = 8, fold # 4, error = 0.2 \n",
      "kNN for k = 8, fold # 5, error = 0.0 \n",
      "kNN for k = 8, fold # 6, error = 0.0 \n",
      "kNN for k = 8, fold # 7, error = 0.0 \n",
      "kNN for k = 8, fold # 8, error = 0.0 \n",
      "kNN for k = 8, fold # 9, error = 0.0 \n",
      "kNN for k = 9, fold # 0, error = 0.0 \n",
      "kNN for k = 9, fold # 1, error = 0.0 \n",
      "kNN for k = 9, fold # 2, error = 0.0 \n",
      "kNN for k = 9, fold # 3, error = 0.0 \n",
      "kNN for k = 9, fold # 4, error = 0.2 \n",
      "kNN for k = 9, fold # 5, error = 0.0 \n",
      "kNN for k = 9, fold # 6, error = 0.0 \n",
      "kNN for k = 9, fold # 7, error = 0.0 \n",
      "kNN for k = 9, fold # 8, error = 0.0 \n",
      "kNN for k = 9, fold # 9, error = 0.0 \n",
      "kNN for k = 10, fold # 0, error = 0.0 \n",
      "kNN for k = 10, fold # 1, error = 0.0 \n",
      "kNN for k = 10, fold # 2, error = 0.0 \n",
      "kNN for k = 10, fold # 3, error = 0.0 \n",
      "kNN for k = 10, fold # 4, error = 0.0 \n",
      "kNN for k = 10, fold # 5, error = 0.0 \n",
      "kNN for k = 10, fold # 6, error = 0.0 \n",
      "kNN for k = 10, fold # 7, error = 0.0 \n",
      "kNN for k = 10, fold # 8, error = 0.0 \n",
      "kNN for k = 10, fold # 9, error = 0.0 \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest average error: 0.0\n",
      "Best k: 6\n"
     ]
    }
   ],
   "source": [
    "K = 10 # Find the best k hyperparameter in range (1, K)\n",
    "numFolds = 10 # Number of folds for cross validation\n",
    "\n",
    "cross_val_best_k = k_fold_cross_validation(K, numFolds, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `accuracy_based_validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 393.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k=1: 0.9\n",
      "Accuracy for k=2: 0.9\n",
      "Accuracy for k=3: 0.88\n",
      "Accuracy for k=4: 0.88\n",
      "Accuracy for k=5: 0.88\n",
      "Accuracy for k=6: 0.9\n",
      "Accuracy for k=7: 0.86\n",
      "Accuracy for k=8: 0.86\n",
      "Accuracy for k=9: 0.86\n",
      "Accuracy for k=10: 0.86\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best dev accuracy: 0.9\n",
      "Best k: 1\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "acc_based_best_k = accuracy_based_validation(K, X_train, y_train, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom kNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the `k_fold_cross_validation` result as $k$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the values of the accuracy, precision, recall and f1-score metrics are presented for the train set. We anticipate the scores to equal 1.0 for the train set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_k = cross_val_best_k\n",
    "\n",
    "# Training kNN Classifier\n",
    "knn_custom = kNN(best_k) \n",
    "knn_custom.fit(X_train, y_train)\n",
    "\n",
    "# Using kNN Classifier (train set)\n",
    "y_custom = knn_custom.predict(X_train)\n",
    "print(classification_report(y_train, y_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the values of the same metrics are presented for the test set. We anticipate lower values for the respective metrics than those calculated for the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using kNN Classifier (test set)\n",
    "y_custom = knn_custom.predict(X_test)\n",
    "print(classification_report(y_test, y_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the `accuracy_based_validation` result as $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the process for both the train set and the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.93      0.97        15\n",
      "           2       0.94      1.00      0.97        16\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_k = acc_based_best_k\n",
    "\n",
    "# Training kNN Classifier\n",
    "knn_custom = kNN(best_k) \n",
    "knn_custom.fit(X_train, y_train)\n",
    "\n",
    "# Using kNN Classifier (train set)\n",
    "y_custom = knn_custom.predict(X_train)\n",
    "print(classification_report(y_train, y_custom))\n",
    "\n",
    "# Using kNN Classifier (test set)\n",
    "y_custom = knn_custom.predict(X_test)\n",
    "print(classification_report(y_test, y_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the result of `k_fold_cross_validation` performs better on the test set (while on the train set both results yield maximum scores, as expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-Learn kNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As implied by the last observation, the result of `k_fold_cross_validation` performs better and hence we will use it to train the Scikit-Learn's algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the values of the accuracy, precision, recall and f1-score metrics are presented for the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_k = cross_val_best_k\n",
    "\n",
    "# Training kNN Classifier\n",
    "knn_scikit = KNeighborsClassifier(n_neighbors=best_k) \n",
    "knn_scikit.fit(X_train, y_train)\n",
    "\n",
    "# Using kNN Classifier (train set)\n",
    "y_scikit = knn_scikit.predict(X_train)\n",
    "print(classification_report(y_train, y_scikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the values of the same metrics are presented for the test set. We anticipate lower values for the respective metrics than those calculated for the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using kNN Classifier (test set)\n",
    "y_scikit = knn_scikit.predict(X_test)\n",
    "print(classification_report(y_test, y_scikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kMeans:\n",
    "    def __init__(self, k, max_iters):\n",
    "        # k = number of clusters\n",
    "        self.k = k\n",
    "        # define the maximum number of iterations\n",
    "        self.max_iters = max_iters\n",
    "        # the centroids for all labels\n",
    "        self.centroids = None\n",
    "\n",
    "    @staticmethod\n",
    "    def cost_function(X, c, labels): \n",
    "        return 0.5*sum(Distance.squared_euclidean_distance(X[i].reshape((1,X[i].shape[0])), c[labels[i]]) for i in range(X.shape[0]))\n",
    "    \n",
    "    def fit(self, X):\n",
    "        # Choose k random points of data as centroids\n",
    "        indices = np.random.choice(X.shape[0], self.k, replace=False)\n",
    "        self.centroids = X[indices]\n",
    "\n",
    "        costs = list()\n",
    "\n",
    "        for iter in range(self.max_iters):\n",
    "            # Expectation step\n",
    "            labels = self.predict(X)  # Assign each data point to the nearest centroid\n",
    "            costs.append(self.cost_function(X, self.centroids, labels).item()) # Calculate the cost \n",
    "\n",
    "            # Maximization step\n",
    "            new_centroids = np.array([np.mean(X[labels == label], axis=0) for label in range(self.k)])\n",
    "            costs.append(self.cost_function(X, new_centroids, labels).item()) # Calculate the new cost\n",
    "            \n",
    "            # If the algorithm has converged, then stop\n",
    "            if np.all(self.centroids == new_centroids):\n",
    "                break\n",
    "                \n",
    "            self.centroids = new_centroids\n",
    "\n",
    "        iters = len(costs)//2\n",
    "        return costs, iters\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Assign each data point to the nearest centroid \n",
    "        distances = np.array([Distance.squared_euclidean_distance(self.centroids, x) for x in X])\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡We will use the KMeans algorithm to cluster the observations of the training set (X_train), as clustering is commonly performed for grouping existing observations rather than predicting the cluster to which a new observation would belong. \n",
    "\n",
    "❗For evaluating the algorithm's performance, it is crucial to note that the cluster labels assigned by KMeans may not necessarily align with the true class labels. Therefore, other evaluation metrics should be employed, that take into account whether observations that normally belong to the same class are indeed found in the same cluster.\n",
    "\n",
    "✔️We are going to use 3 commonly used clustering performance evaluation metrics (given that the ground truth is known):\n",
    "1. <b>Adjusted Rand Index</b>: It is a function that measures the similarity of the two assignments, ignoring permutations:\n",
    "    - $ARI = (RI - Expected_{RI}) / (max(RI) - Expected_{RI})$ <br> where $RI$ = (number of agreeing pairs) / (number of pairs)\n",
    "    - The score range is [-1, 1]. Lower values indicate different labelings, similar clusterings have a high index and 1 is the perfect match score.\n",
    "\n",
    "<br>\n",
    "    \n",
    "2. <b>Adjusted Mutual Information</b>: It is a function that measures the agreement of the two assignments, ignoring permutations. Two different normalized versions of this measure are available, Normalized Mutual Information (NMI) and Adjusted Mutual Information (AMI). NMI is often used in the literature, while AMI was proposed more recently and is normalized against chance. We will use AMI.\n",
    "    - Values close to 0 indicate two label assignments that are largely independent, while values close to 1 indicate significant agreement. Further, an AMI of exactly 1 indicates that the two label assignments are equal (with or without permutation).\n",
    "\n",
    "<br>\n",
    "\n",
    "3. <b>Fowlkes-Mallows Index</b>: It is defined as the geometric mean of the pairwise precision and recall:\n",
    "    - $FMI = \\frac{TP}{\\sqrt{(TP+FP)(TP+FN)}}$\n",
    "    - The score ranges from 0 to 1. A high value indicates a good similarity between two clusters.\n",
    "\n",
    "[Clustering performance evaluation](https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index (ARI):  0.7360751198434404\n",
      "Adjusted Mutual Information (AMI):  0.7783243538894051\n",
      "Fowlkes-Mallows Index (FM):  0.8244785330650813\n"
     ]
    }
   ],
   "source": [
    "num_of_classes = len(np.unique(y_train))\n",
    "max_iters = 100\n",
    "\n",
    "# Training k-means\n",
    "k_means_custom = kMeans(num_of_classes, max_iters) \n",
    "costs, iters = k_means_custom.fit(X_train)\n",
    "\n",
    "# Using k-means \n",
    "y_custom = k_means_custom.predict(X_train)\n",
    "\n",
    "# Evaluation of clustering performance using appropriate metrics\n",
    "ari = metrics.adjusted_rand_score(y_train, y_custom)\n",
    "ami = metrics.adjusted_mutual_info_score(y_train, y_custom)\n",
    "fm = metrics.fowlkes_mallows_score(y_train, y_custom)\n",
    "\n",
    "print(\"Adjusted Rand Index (ARI): \", ari)\n",
    "print(\"Adjusted Mutual Information (AMI): \", ami)\n",
    "print(\"Fowlkes-Mallows Index (FM): \", fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations run:  6\n",
      "Final Cost:  13.715240950226248\n",
      "Centroids: \n",
      " [[5.78235294 2.65882353 4.37647059 1.47647059]\n",
      " [6.76153846 3.09230769 5.79230769 2.06923077]\n",
      " [5.005      3.41       1.445      0.245     ]]\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(\"Iterations run: \", iters)\n",
    "print(\"Final Cost: \", costs[-1])\n",
    "print(\"Centroids: \\n\", k_means_custom.centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iteration</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0a</th>\n",
       "      <td>E-step</td>\n",
       "      <td>159.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0b</th>\n",
       "      <td>M-step</td>\n",
       "      <td>45.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1a</th>\n",
       "      <td>E-step</td>\n",
       "      <td>28.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b</th>\n",
       "      <td>M-step</td>\n",
       "      <td>17.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2a</th>\n",
       "      <td>E-step</td>\n",
       "      <td>16.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2b</th>\n",
       "      <td>M-step</td>\n",
       "      <td>15.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3a</th>\n",
       "      <td>E-step</td>\n",
       "      <td>14.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3b</th>\n",
       "      <td>M-step</td>\n",
       "      <td>13.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4a</th>\n",
       "      <td>E-step</td>\n",
       "      <td>13.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4b</th>\n",
       "      <td>M-step</td>\n",
       "      <td>13.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a</th>\n",
       "      <td>E-step</td>\n",
       "      <td>13.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5b</th>\n",
       "      <td>M-step</td>\n",
       "      <td>13.715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Step    Cost  \n",
       "Iteration                 \n",
       "0a         E-step  159.050\n",
       "0b         M-step   45.942\n",
       "1a         E-step   28.705\n",
       "1b         M-step   17.982\n",
       "2a         E-step   16.536\n",
       "2b         M-step   15.285\n",
       "3a         E-step   14.192\n",
       "3b         M-step   13.843\n",
       "4a         E-step   13.810\n",
       "4b         M-step   13.715\n",
       "5a         E-step   13.715\n",
       "5b         M-step   13.715"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The evolution of the cost function\n",
    "report_cost_evolution = Curve.EM_alg_cost_evolution_curve(costs)\n",
    "display(report_cost_evolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-learn k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index (ARI):  0.7360751198434404\n",
      "Adjusted Mutual Information (AMI):  0.7783243538894051\n",
      "Fowlkes-Mallows Index (FM):  0.8244785330650813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alvio\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# Training k-means\n",
    "k_means_scikit = KMeans(n_clusters=num_of_classes, init=\"random\")\n",
    "k_means_scikit.fit(X_train)\n",
    "\n",
    "# Using k-means\n",
    "y_scikit = k_means_scikit.predict(X_train)\n",
    "\n",
    "# Evaluate clustering performance using appropriate metrics\n",
    "ari = metrics.adjusted_rand_score(y_train, y_scikit)\n",
    "ami = metrics.adjusted_mutual_info_score(y_train, y_scikit)\n",
    "fm = metrics.fowlkes_mallows_score(y_train, y_scikit)\n",
    "\n",
    "print(\"Adjusted Rand Index (ARI): \", ari)\n",
    "print(\"Adjusted Mutual Information (AMI): \", ami)\n",
    "print(\"Fowlkes-Mallows Index (FM): \", fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations run:  9\n",
      "Final Cost:  13.715240950226244\n",
      "Centroids: \n",
      " [[5.005      3.41       1.445      0.245     ]\n",
      " [5.78235294 2.65882353 4.37647059 1.47647059]\n",
      " [6.76153846 3.09230769 5.79230769 2.06923077]]\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(\"Iterations run: \", k_means_scikit.n_iter_)\n",
    "print(\"Final Cost: \", 1/2 * k_means_scikit.inertia_)    # inertia does not include an 1/2 factor as we did in our implementation, so we need to multiply it to be able to compare the 2 costs\n",
    "print(\"Centroids: \\n\", k_means_scikit.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SVD & Classic PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, m):\n",
    "        self.m = m\n",
    "\n",
    "    def svd_reduction(self, X):\n",
    "        U, S, V = np.linalg.svd(X, full_matrices=False)\n",
    "        print( \"U\", U.shape, \"S\", S.shape, \"V\", V.shape )\n",
    "        mu = X.mean(axis=0)\n",
    "\n",
    "        eigvecs = V[:self.m,:]\n",
    "        eigvals = S[:self.m]\n",
    "        print( 'X', X.shape, 'eigvecs', eigvecs.shape, 'eigvals', eigvals.shape )\n",
    "        Z = (X-mu).dot(eigvecs.T)\n",
    "        print( 'Z', Z.shape )\n",
    "        return Z, eigvecs, eigvals, mu\n",
    "    \n",
    "    def classic_reduction(self, X):\n",
    "        mu = X.mean(axis=0).reshape( (1,-1) )\n",
    "\n",
    "        normalized_X = X-mu\n",
    "\n",
    "        S = (1/X.shape[0]) * normalized_X.T.dot( normalized_X )\n",
    "\n",
    "        eigvectors, eigvals = self.eigsort( S )\n",
    "\n",
    "        U = eigvectors[:,:self.m]\n",
    "        Lambdas = eigvals[:self.m]\n",
    "        print( X.shape, U.shape, Lambdas.shape )\n",
    "\n",
    "        Z = normalized_X.dot(U)\n",
    "        return Z, U, Lambdas, mu\n",
    "    \n",
    "    def eigsort(self, A):\n",
    "        eigvals, U = np.linalg.eig(A)\n",
    "        # sort eigenvalues in descending order\n",
    "        order = np.argsort(eigvals)[::-1]\n",
    "        eigvals = eigvals[order]\n",
    "        #re-arrange the eigenvectors\n",
    "        U = U[:,order]\n",
    "        return U, eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U (50, 4) S (4,) V (4, 4)\n",
      "X (50, 4) eigvecs (3, 4) eigvals (3,)\n",
      "Z (50, 3)\n",
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "m = 3\n",
    "\n",
    "iris_data = load_iris(as_frame=True)\n",
    "iris_data.frame\n",
    "\n",
    "# split initial data into train and test (50 examples for test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data.to_numpy(), \n",
    "                                                    iris_data.target.to_numpy(), \n",
    "                                                    test_size=50)\n",
    "\n",
    "\n",
    "# split rest of the train data into train and dev (50 examples for dev)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, \n",
    "                                                  test_size=50)\n",
    "\n",
    "pca = PCA(m)\n",
    "z, eva, eve, mu = pca.svd_reduction(X_train)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 4) (4, 3) (3,)\n",
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "z, u, eva, mu = pca.classic_reduction(X_train)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a classification problem with  classes, with a 1-of-K binary coding scheme for the target vector t. Each class $C_k$ has its own linear model.\n",
    "\n",
    "Each class $C_k$ is described by its own linear model so that: $y_k(\\mathbf{x})=\\mathbf{w}_k^T \\mathbf{x} + w_{k0}$ where k=1,...,K, or, using vector notation: $$\\mathbf{ y(x) = {\\tilde W}^T \\tilde x }$$\n",
    "\n",
    "where $\\mathbf{\\tilde W}$ is a matrix whose $k^{th}$ column comprises the $D+1$-dimensional vector $ \\mathbf {\\tilde w}_k = (w_{k0} ; \\mathbf{w}_k^T)^T$ and $ \\mathbf {\\tilde x}$ is the corresponding augmented input vector $(1;\\mathbf{x}^T)^T$ with a dummy input $x_0 = 1$. Assign new input $\\mathbf x$ to the class $C_k$ if $k=argmax\\;y_j (\\mathbf x)$. Consider a training data set $\\{\\mathbf {x}_n, \\mathbf {t}_n \\}$ where $n=1,...,N$ and define a matrix $\\mathbf T$ whose $n^{th}$ row is the vector $\\mathbf{t}_n^T$.\n",
    "\n",
    "The sum-of-squares error function can then be written as:\n",
    "$E_D(\\mathbf{\\tilde W}) = \\frac{1}{2}Tr((\\mathbf{\\tilde{X} \\tilde{W} - T})^T(\\mathbf{\\tilde{X} \\tilde{W} - T}))$.\n",
    "\n",
    "➡️  Setting the derrivative wrt $\\tilde W$ to zero, and rearranging, we obtain the solution:\n",
    "$\\mathbf {\\tilde{W} = (\\tilde{X}^T\\tilde{X})^{-1}\\tilde{X}^TT}$, where $(\\tilde{X}^T\\tilde{X})^{-1}\\tilde{X}^T$ is the pseudo-inverse of $\\mathbf{\\tilde X}.$\n",
    "\n",
    "➡️  We then obtain the discriminant function in the form $\\mathbf{ y(x) = {\\tilde W}^T \\tilde x }$ \n",
    "\n",
    "<i>Bishop, C. M. (2006). Pattern Recognition and Machine Learning (Chapter 4.1.3: Least Squares for Classification).</i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To implement the algorithm described above, during fit we first covert `y_train` to one-hot-vectors (matrix $\\mathbf T$) and then learn the weights (matrix $\\mathbf W$) using the above formula. Predict is implemented exactly as derscibed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Least Squares Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeastSquares:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.W = None\n",
    "        self.num_classes = None    \n",
    "        \n",
    "    def _one_hot_vector(self, x):\n",
    "        vector = np.zeros(self.num_classes).astype(int)\n",
    "        vector[x] = 1\n",
    "        return vector\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.num_classes = np.unique(y_train).shape[0]\n",
    "        \n",
    "        # Insert 1 as the first column in X to augment the input vectors with a dummy input x_0 = 1\n",
    "        X = np.insert(X_train, 0, 1, axis=1)\n",
    "        \n",
    "        # T: T[i] = one-hot vector for the class of example i\n",
    "        T = list(map(self._one_hot_vector, y_train))\n",
    "        \n",
    "        # W: W = pseudo_inverse(X) * T\n",
    "        self.W = np.linalg.pinv(X).dot(T)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Insert 1 as the first column in X to augment the input vectors with a dummy input x_0 = 1\n",
    "        X = np.insert(X_test, 0, 1, axis=1)\n",
    "        \n",
    "        # Y: Y = transpose(W) * transpose(X)\n",
    "        Y = self.W.T.dot(X.T)\n",
    "\n",
    "        classes = np.argmax(Y, axis=0)\n",
    "        \n",
    "        return classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Least Squares Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the values of the accuracy, precision, recall and f1-score metrics are presented for the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       0.71      0.45      0.56        11\n",
      "           2       0.74      0.89      0.81        19\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.82      0.78      0.79        50\n",
      "weighted avg       0.84      0.84      0.83        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Least Squares Classifier\n",
    "least_squares = LeastSquares()\n",
    "least_squares.fit(X_train, y_train)\n",
    "\n",
    "# Using Least Squares Classifier (train set)\n",
    "y_custom = least_squares.predict(X_train)\n",
    "print(classification_report(y_train, y_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the values of the same metrics are presented for the test set. We anticipate lower values for the respective metrics than those calculated for the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.33      0.50        15\n",
      "           2       0.62      1.00      0.76        16\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.87      0.78      0.75        50\n",
      "weighted avg       0.88      0.80      0.77        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Least Squares Classifier (test set)\n",
    "y_custom = least_squares.predict(X_test)\n",
    "print(classification_report(y_test, y_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights learned during training (matrix $\\mathbf W$) are displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights learned: \n",
      " [[ 0.20670856  1.39324362 -0.59995218]\n",
      " [ 0.04454683 -0.03654124 -0.00800559]\n",
      " [ 0.24956203 -0.37230851  0.12274649]\n",
      " [-0.22091457  0.1878363   0.03307826]\n",
      " [-0.03456185 -0.43165908  0.46622093]]\n"
     ]
    }
   ],
   "source": [
    "# Print the weights that were learned during the training\n",
    "print(\"Weights learned: \\n\",least_squares.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-Learn Ridge Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the values of the accuracy, precision, recall and f1-score metrics are presented for the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       0.71      0.45      0.56        11\n",
      "           2       0.74      0.89      0.81        19\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.82      0.78      0.79        50\n",
      "weighted avg       0.84      0.84      0.83        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Ridge Classifier\n",
    "scikit_ridge = RidgeClassifier(alpha=0) # alpha=0 means no regularization\n",
    "scikit_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Using Ridge Classifier (train set)\n",
    "y_scikit = scikit_ridge.predict(X_train)\n",
    "print(classification_report(y_train, y_scikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the values of the same metrics are presented for the test set. We anticipate lower values for the respective metrics than those calculated for the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.33      0.50        15\n",
      "           2       0.62      1.00      0.76        16\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.87      0.78      0.75        50\n",
      "weighted avg       0.88      0.80      0.77        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Ridge Classifier (test set)\n",
    "y_scikit = scikit_ridge.predict(X_test)\n",
    "print(classification_report(y_test, y_scikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights learned during training are displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights learned: \n",
      " [[ 0.08909365  0.49912405 -0.44182913 -0.06912371]\n",
      " [-0.07308247 -0.74461703  0.37567261 -0.86331815]\n",
      " [-0.01601118  0.24549297  0.06615653  0.93244186]]\n"
     ]
    }
   ],
   "source": [
    "# Print the weights that were learned during the training\n",
    "print(\"Weights learned: \\n\",scikit_ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this section, the Logistic Regression classification algorithm is implemented. Our model is trained using the Stochastic Gradient Descent algorithm, and the Cross-Entropy Loss is used as the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight update rule given that the loss function is Cross Entropy Loss, is the following:\n",
    "\n",
    "$$weight = weight - \\eta * gradient$$\n",
    "where:\n",
    "- $\\eta$: learning rate\n",
    "- $gradient=outer(example,\\; probabilities−one\\; hot\\; label)$\n",
    "\n",
    "---\n",
    "\n",
    "Let's break down the maths behind the weight update rule:\n",
    "\n",
    "1. <b>The cross-entropy loss for a single training example is given by:</b>\n",
    "    $$L(\\hat y, y) = - \\sum_i{y_i}log(\\hat y_i)$$\n",
    "    where:\n",
    "    - $\\hat y_i$: the predicted probability for class $i$ (through $softmax$)\n",
    "    - $y_i$: the corresponding element of the one-hot encoded true label vector\n",
    "\n",
    "2. <b>The softmax activation function is used to convert raw scores (logits) into probabilities:</b>\n",
    "    $$softmax(\\mathbf t)_j = \\frac{exp(\\mathbf t_j)}{\\sum_{k=1}^K{exp(\\mathbf t_k)}}$$\n",
    "    where:\n",
    "    - $\\mathbf t$: the vector of logits\n",
    "    - $K$: the number of classes\n",
    "\n",
    "3. <b> The gradient of Cross-Entropy Loss w.r.t. the weights is:</b>\n",
    "    $$ \\frac{\\partial L}{\\partial \\mathbf W_{ij}} = x_i(\\hat y_j - y_j)$$\n",
    "    Explanation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, n_iters, learning_rate, regularizator):\n",
    "        self.n_iters = n_iters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularizator = regularizator\n",
    "        self.W = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(t):\n",
    "        return np.exp(t) / np.sum(np.exp(t))  \n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "        num_examples, num_features = X_train.shape\n",
    "        num_classes = len(np.unique(y_train))\n",
    "\n",
    "        # insert 1 as the first column in X to augment the input vectors with a dummy input x_0 = 1\n",
    "        X = np.insert(X_train, 0, 1, axis=1) \n",
    "\n",
    "        # insert y_train array to shuffle examples in for loop\n",
    "        F = np.insert(X, 0, y_train, axis=1)     \n",
    "\n",
    "        # initialize the weights W\n",
    "        self.W = np.zeros((num_features + 1, num_classes))\n",
    "\n",
    "        best_accuracy = 0\n",
    "        best_epoch = 0\n",
    "        n_epochs_unchanged = 0\n",
    "\n",
    "        for epoch in range(1, self.n_iters+1):\n",
    "            np.random.shuffle(F)                    #random permutation of examples\n",
    "            X = F[:,1:]\n",
    "            y_train = F[:,0]\n",
    "            for i in range(num_examples):\n",
    "                example = X[i]  \n",
    "                logits = self.W.T.dot(example)  # (D,K)-->(K,D) *   (D,) \n",
    "                probabilities = self.softmax(logits)\n",
    "                one_hot_vector = np.zeros(num_classes)\n",
    "                one_hot_vector[int(y_train[i])] = 1\n",
    "\n",
    "                # weight_modification = self.learning_rate * np.outer(example, probabilities - one_hot_vector)\n",
    "                # self.W = (1 - 2 * self.regularizator * self.learning_rate) * self.W - weight_modification\n",
    "\n",
    "                self.W = self.W - self.learning_rate * np.outer(example, probabilities - one_hot_vector)\n",
    "                # (D,K)                                  (D,K)     #(D,)       (K,)         (K,)\n",
    "\n",
    "            # Early Stopping\n",
    "            accuracy = accuracy_score(y_val, self.predict(X_val))\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_epoch = epoch\n",
    "                best_weights = self.W\n",
    "                n_epochs_unchanged = 0\n",
    "            else:\n",
    "                n_epochs_unchanged += 1\n",
    "\n",
    "            if n_epochs_unchanged == 20:\n",
    "                self.W = best_weights\n",
    "                break  \n",
    "\n",
    "        print(\"Best epoch: \"+str(best_epoch))\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X = np.insert(X_test, 0, 1, axis=1)   #insert 1 in x_vector for w0\n",
    "\n",
    "        y_pred = list()\n",
    "        for example in X:\n",
    "            y_pred.append(np.argmax(self.softmax(self.W.T.dot(example))))\n",
    "\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,4) (4,3) (3,4) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training Logistic Regression Classifier\u001b[39;00m\n\u001b[0;32m      2\u001b[0m logistic_regression \u001b[38;5;241m=\u001b[39m LogisticRegression(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mlogistic_regression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Using Logistic Regression Classifier\u001b[39;00m\n\u001b[0;32m      6\u001b[0m y_custom \u001b[38;5;241m=\u001b[39m logistic_regression\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[1;32mIn[109], line 27\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X_train, y_train)\u001b[0m\n\u001b[0;32m     25\u001b[0m error \u001b[38;5;241m=\u001b[39m probabilities \u001b[38;5;241m-\u001b[39m (yi \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_train))\n\u001b[0;32m     26\u001b[0m gradient \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(xi, error)\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m gradient\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,4) (4,3) (3,4) "
     ]
    }
   ],
   "source": [
    "# Training Logistic Regression Classifier\n",
    "logistic_regression = LogisticRegression(100, 0.01, 0)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Using Logistic Regression Classifier\n",
    "y_custom = logistic_regression.predict(X_test)\n",
    "print(classification_report(y_test, y_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-Learn Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.68      1.00      0.81        15\n",
      "           2       1.00      0.56      0.72        16\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.89      0.85      0.84        50\n",
      "weighted avg       0.90      0.86      0.85        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training SGD Classifier\n",
    "scikit_sgd = SGDClassifier(loss=\"log_loss\", max_iter=100, early_stopping=True, learning_rate='optimal', eta0=0.01, alpha=0.0001) #loss='log_loss', max_iter=100, early_stopping=True\n",
    "scikit_sgd.fit(X_train, y_train)\n",
    "\n",
    "# Using SGD Classifier\n",
    "y_scikit = scikit_sgd.predict(X_test)\n",
    "print(classification_report(y_test, y_scikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a general case where we are in $R^d$. We assume that the population from which our data is sampled follows a normal distribution $N(μ, Σ)$. To apply Naive Bayes in $R^d$, we choose to approximate this distribution with a second distribution $N(m, C)$, where $C$ is a diagonal covariance matrix. The latter implies that we consider independence among the variables, leading to zero covariances (and thus a diagonal covariance matrix $C$ where only $COV(X_i, X_i) = VAR(X_i) \\geq 0$, for $i=1,...,d)$.\n",
    "\n",
    "Let $θ = (μ, Σ)$ and $φ = (m, C)$.\n",
    "\n",
    "Now, we can approach the distribution $N(μ, Σ)$ in two ways:\n",
    "1. Choose $φ$ s.t. $KL(θ : φ)$ is minimized\n",
    "2. Choose $φ$ s.t. $KL(φ : θ)$ is minimized, where KL is the Kullback-Liebler divergence\n",
    "\n",
    "These approaches lead to the following formulas, respectively:\n",
    "1. $m = μ$, $C = diag(Σ)$\n",
    "2. $m = μ$, $C = diag(Λ)^{-1}$, where $Λ$ is the precision matrix (i.e. $Λ = Σ^{-1}$)\n",
    "\n",
    "In the following implementation we use the first formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.priors = None\n",
    "        self.means = None\n",
    "        self.covariances = None\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.classes = np.unique(y_train)\n",
    "        self.priors = {}\n",
    "        self.means = {}\n",
    "        self.covariances = {}\n",
    "        \n",
    "        for c in self.classes:\n",
    "            # Separate examples per class \n",
    "            class_data = X_train[y_train == c]\n",
    "            \n",
    "            # Calculate the prior probability for each class\n",
    "            self.priors[c] = class_data.shape[0] / X_train.shape[0]\n",
    "\n",
    "            # Calculate the mean vector for each class: m = [mean(f1), mean(f2),...]\n",
    "            self.means[c] = np.mean(class_data, axis=0)\n",
    "            \n",
    "            # Calculate the covariance vector for each class: C = diag(var(f1), var(f2),...). Note that only the diagonal needs to be stored\n",
    "            self.covariances[c] = np.var(class_data, axis=0)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = list()\n",
    "\n",
    "        for example in X_test:\n",
    "            class_prob = []\n",
    "            for c in self.classes:\n",
    "                # P(c|example) ~ P(c) * P(example|c) = P(c) * P(example|m_c, C_c)\n",
    "                class_prob.append(self.priors[c] * multivariate_normal.pdf(example, mean = self.means[c], cov=self.covariances[c]))\n",
    "            predictions.append(self.classes[np.argmax(class_prob)])\n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the values of the accuracy, precision, recall and f1-score metrics are presented for the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       0.92      1.00      0.96        11\n",
      "           2       1.00      0.95      0.97        19\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.97      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Gaussian Naive Bayes Classifier\n",
    "gaussian_nb = GaussianNaiveBayes()\n",
    "gaussian_nb.fit(X_train, y_train)\n",
    "\n",
    "# Using Gaussian Naive Bayes Classifier (train set)\n",
    "y_custom = gaussian_nb.predict(X_train)\n",
    "print(classification_report(y_train, y_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the values of the same metrics are presented for the test set. We anticipate lower values for the respective metrics than those calculated for the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.73      0.85        15\n",
      "           2       0.80      1.00      0.89        16\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.93      0.91      0.91        50\n",
      "weighted avg       0.94      0.92      0.92        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Gaussian Naive Bayes Classifier (test set)\n",
    "y_custom = gaussian_nb.predict(X_test)\n",
    "print(classification_report(y_test, y_custom))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters (priors, means and covariance matrix) are displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Gaussian Naive Bayes Classifier - Priors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Class_0</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class_0  Class_1  Class_2\n",
       "0    0.4     0.22     0.38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Gaussian Naive Bayes Classifier  - Means\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Class_0</th>\n",
       "      <td>5.005</td>\n",
       "      <td>3.410</td>\n",
       "      <td>1.445</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_1</th>\n",
       "      <td>5.745</td>\n",
       "      <td>2.673</td>\n",
       "      <td>4.045</td>\n",
       "      <td>1.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_2</th>\n",
       "      <td>6.474</td>\n",
       "      <td>2.947</td>\n",
       "      <td>5.537</td>\n",
       "      <td>2.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature_0  Feature_1  Feature_2  Feature_3\n",
       "Class_0    5.005      3.410      1.445      0.245  \n",
       "Class_1    5.745      2.673      4.045      1.227  \n",
       "Class_2    6.474      2.947      5.537      2.026  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Gaussian Naive Bayes Classifier  - Covariance Matrix per class\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature_0</th>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature_0  Feature_1  Feature_2  Feature_3\n",
       "Feature_0    0.123      0.000      0.000      0.000  \n",
       "Feature_1    0.000      0.176      0.000      0.000  \n",
       "Feature_2    0.000      0.000      0.026      0.000  \n",
       "Feature_3    0.000      0.000      0.000      0.011  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature_0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature_0  Feature_1  Feature_2  Feature_3\n",
       "Feature_0    0.23       0.000      0.000      0.000  \n",
       "Feature_1    0.00       0.071      0.000      0.000  \n",
       "Feature_2    0.00       0.000      0.222      0.000  \n",
       "Feature_3    0.00       0.000      0.000      0.037  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature_0</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature_0  Feature_1  Feature_2  Feature_3\n",
       "Feature_0    0.375      0.000      0.000      0.000  \n",
       "Feature_1    0.000      0.117      0.000      0.000  \n",
       "Feature_2    0.000      0.000      0.277      0.000  \n",
       "Feature_3    0.000      0.000      0.000      0.082  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the estimated priors (per class), means (per class and feature) and covariances(per class and feature)\n",
    "custom_priors = np.asarray(list(gaussian_nb.priors.values()))\n",
    "custom_means = np.asarray(list(gaussian_nb.means.values()))\n",
    "custom_num_classes = len(gaussian_nb.classes)\n",
    "custom_covariances = np.array([np.diag(list(gaussian_nb.covariances.values())[i]) for i in range(custom_num_classes)])\n",
    "\n",
    "Report.gaussian_naive_bayes_parameters(\"Custom Gaussian Naive Bayes Classifier\", custom_priors, custom_means, custom_covariances, custom_num_classes, X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-Learn Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the values of the accuracy, precision, recall and f1-score metrics are presented for the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       0.92      1.00      0.96        11\n",
      "           2       1.00      0.95      0.97        19\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.97      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training GaussianNB Classifier\n",
    "scikit_gaussian_nb = GaussianNB()\n",
    "scikit_gaussian_nb.fit(X_train, y_train)\n",
    "\n",
    "# Using GaussianNB Classifier (train set)\n",
    "y_scikit = scikit_gaussian_nb.predict(X_train)\n",
    "print(classification_report(y_train, y_scikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the values of the same metrics are presented for the test set. We anticipate lower values for the respective metrics than those calculated for the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.73      0.85        15\n",
      "           2       0.80      1.00      0.89        16\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.93      0.91      0.91        50\n",
      "weighted avg       0.94      0.92      0.92        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using GaussianNB Classifier (test set)\n",
    "y_scikit = scikit_gaussian_nb.predict(X_test)\n",
    "print(classification_report(y_test, y_scikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters (priors, means and covariance matrix) are displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-Learn Gaussian Naive Bayes Classifier - Priors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Class_0</th>\n",
       "      <th>Class_1</th>\n",
       "      <th>Class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class_0  Class_1  Class_2\n",
       "0    0.4     0.22     0.38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-Learn Gaussian Naive Bayes Classifier  - Means\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Class_0</th>\n",
       "      <td>5.005</td>\n",
       "      <td>3.410</td>\n",
       "      <td>1.445</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_1</th>\n",
       "      <td>5.745</td>\n",
       "      <td>2.673</td>\n",
       "      <td>4.045</td>\n",
       "      <td>1.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_2</th>\n",
       "      <td>6.474</td>\n",
       "      <td>2.947</td>\n",
       "      <td>5.537</td>\n",
       "      <td>2.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature_0  Feature_1  Feature_2  Feature_3\n",
       "Class_0    5.005      3.410      1.445      0.245  \n",
       "Class_1    5.745      2.673      4.045      1.227  \n",
       "Class_2    6.474      2.947      5.537      2.026  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-Learn Gaussian Naive Bayes Classifier  - Covariance Matrix per class\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature_0</th>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature_0  Feature_1  Feature_2  Feature_3\n",
       "Feature_0    0.123      0.000      0.000      0.000  \n",
       "Feature_1    0.000      0.176      0.000      0.000  \n",
       "Feature_2    0.000      0.000      0.026      0.000  \n",
       "Feature_3    0.000      0.000      0.000      0.011  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature_0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature_0  Feature_1  Feature_2  Feature_3\n",
       "Feature_0    0.23       0.000      0.000      0.000  \n",
       "Feature_1    0.00       0.071      0.000      0.000  \n",
       "Feature_2    0.00       0.000      0.222      0.000  \n",
       "Feature_3    0.00       0.000      0.000      0.037  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature_0</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature_3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature_0  Feature_1  Feature_2  Feature_3\n",
       "Feature_0    0.375      0.000      0.000      0.000  \n",
       "Feature_1    0.000      0.117      0.000      0.000  \n",
       "Feature_2    0.000      0.000      0.277      0.000  \n",
       "Feature_3    0.000      0.000      0.000      0.082  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the estimated priors (per class), means (per class and feature) and covariances(per class and feature)\n",
    "scikit_priors = scikit_gaussian_nb.class_prior_\n",
    "scikit_means = scikit_gaussian_nb.theta_\n",
    "scikit_num_classes = len(scikit_gaussian_nb.classes_)\n",
    "scikit_covariances = np.array([np.diag(scikit_gaussian_nb.var_[i]) for i in range(scikit_num_classes)])\n",
    "scikit_num_features = scikit_gaussian_nb.n_features_in_\n",
    "\n",
    "Report.gaussian_naive_bayes_parameters(\"Scikit-Learn Gaussian Naive Bayes Classifier\", scikit_priors, scikit_means, scikit_covariances, scikit_num_classes, scikit_num_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
